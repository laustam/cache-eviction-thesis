\chapter{Experimental setup}\label{chapter:experimental-setup}

This chapter outlines the setup of the experiment that was performed, guided by design decisions previously outlined in \Cref{chapter:design}. The experiment can be broken into two main parts: synthetic data generation and cache simulations, discussed in \Cref{subsec: synthetic-data-generation,subsec: cache-simulations}.


\section{System Configuration}

This section briefly mentions notable hardware and software used throughout the development and experimentation of the project.

\begin{description}[style=unboxed, leftmargin=0cm]
    \item[Hardware] The experiments were performed on an Apple MacBook Pro (13-inch, M1, 2020). The system features an Apple M1 chip with an 8-core CPU (4 performance cores, 4 efficiency cores) and an 8-core GPU\footnote{Hardware information: \url{https://support.apple.com/111893}}. The operating system used was macOS Sequoia 15.3.1. Compilation was handled by the Apple Clang compiler, version 15.0.0.
    \item[Software] The simulations were performed using the libCacheSim library (version 0.3.0) as a base, with some notable changes made to support the compilation on the hardware listed above. The cache eviction algorithms used for the simulations were implemented in the C language within the framework while the synthetic workloads were generated by means of Python scripts.
\end{description}


\section{Synthetic Data Generation}\label{subsec: synthetic-data-generation}

The cache simulations utilized synthetic workloads, each sampled from a Zipfian distribution. Each workload consisted of 100,000 requests, each request corresponding to an access to an item identified by an integer value. The set of unique objects within a workload file is defined as its \keyword{working set}. 

For this experiment, workloads were generated with variations of working set size and \keyword{Zipfian skewness parameter} ($\alpha$). The total number of requests generated for each workload was kept constant at a value of \textbf{$100,000$}, to better assess the impact of the working set and $\alpha$. The exact values tested are given in \Cref{tab: data-params}.

\begin{figure}[h!]
    \centering
    \caption{Parameters Used for Zipfian Workload Generation}
    \label{tab: data-params}
    \begin{tabularx}{\textwidth}{lX}
        \toprule
        \textbf{Parameter} & \textbf{Values} \\
        \midrule
        Zipfian skewness parameter ($\alpha$) & 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.4, 1.6 \\
        Working set sizes & 1,000, 2,000, 3,000, 4,000, 5,000, 10,000, 20,000, 30,000, 40,000, 50,000 \\
        Total requests & 100,000 \\
        \bottomrule
    \end{tabularx}
\end{figure}

Referring to \Cref{tab: data-params}, a total of 80 distinct experimental scenarios were generated by combining 8 unique values for the Zipfian skewness parameter $\alpha$ with 10 unique values for the size of the working set. To account for the stochastic nature of the output distribution, each of these 80 scenarios was executed 20 times independently, resulting in a grand total of \keyword{1,600 generated workloads}.

Each generated workload was saved as a text file, where each of the 100,000 lines represented a single request. For the purpose of cache simulations, the integer value on each line represented an item's rank rather than a unique ID. This simplification ensures that lower rank values directly correspond to a higher probability of access, as dictated by the Zipfian distribution's skewness parameter.

\section{Cache Simulations}\label{subsec: cache-simulations}

The cache simulations were performed using the cache simulator provided by the libCacheSim library. Each cache simulation requires specifying three key parameters:

\begin{description}
    \item [1. Workload file (and format)] Each workload used in the experiment is a synthetic one, generated by sampling a Zipfian distribution (see the previous \Cref{subsec: synthetic-data-generation} for more information). A total of $1,600$ unique workload files were generated as text files. Each of these workloads had a total of 100,000 requests with varying working set sizes.
    \item [2. Cache eviction algorithm] Three different cache eviction primitives were used: LRU, FIFO, and SIEVE. More information regarding their design and implementation can be found in \Cref{sec: cache-eviction-algs}.
    \item [3. Cache size] The size of the cache dictates the storage capacity of items that the cache can hold, which is crucial to assess the performance of a simulation run. For the sake of this work, the cache size is taken as relative to a workload's working set size. For example, a relative cache size of 0.1 for a workload with 3,000 unique items would instantiate a cache with a capacity to hold 300 unique items. The following 20 relative cache sizes were used in this experiment: 0.0001, 0.0002, 0.0004, 0.0006, 0.0008, 0.001, 0.002, 0.004, 0.006, 0.008, 0.01, 0.02, 0.04, 0.06, 0.08, 0.1, 0.2, 0.4, 0.6, 0.8. It is noteworthy to mention that not every relative cache size was tested on all workloads, especially lower sizes. More specifically, simulations using workloads with a working set of less than 10,000 items never used a relative cache size of 0.0001 â€” this would result in a cache that could hold no single item. For a more extensive listing of the different minimum relative cache sizes supported by each working set size, see \Cref{appendix: working-set-size-vs-relative-cache-size}.
\end{description}

The libCacheSim library provides a command-line tool to execute cache simulations for different algorithms and cache sizes on a single workload. An example usage is as follows:

\input{report/code/libCacheSim_example}

In this example, the simulator \code{cachesim} uses the workload \code{workload1.txt} which is a \code{txt} file to run cache simulations using the eviction algorithms \code{fifo,lru,sieve} with relative cache sizes of \code{0.1,0.2}.

The \code{cachesim} tool was used to execute 28,851 cache simulations on each of the three algorithms (SIEVE, LRU, FIFO), with a grand total of \keyword{86,553 cache simulations}. Each cache simulation tested a unique configuration of workload file, cache eviction algorithm, and cache size; there was no need for multiple runs of the same configuration due to the measured miss ratio metric being time-independent and deterministic.

It is worth mentioning that the 86,553 tested cache simulations cover only 90.2\% of the 96,000 total simulations expected; the expected amount would be executed if all relative cache sizes could be covered. Ideally, each relative cache size would be tested during 48,000 separate simulations. In practice, we see that this optimal value is only reached with relative cache sizes greater than 0.001. This highlights an imbalance in the experimental design, primarily due to the limitation of 100,000 requests in each workload. A precise overview of the number of simulations per relative cache size is given in \Cref{appendix:relative-cache-size-simulations}.